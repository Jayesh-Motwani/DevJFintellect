{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T19:41:24.597072Z",
     "start_time": "2025-09-22T19:41:24.592020Z"
    }
   },
   "source": [
    "# deepar_test_pipeline.py - Standalone Testing Pipeline\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "from tensorflow.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import shap"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:41:24.964256Z",
     "start_time": "2025-09-22T19:41:24.956256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GaussianLayer(Layer):\n",
    "    \"\"\"\n",
    "    Exact copy of your GaussianLayer - needed for model loading\n",
    "    This must match your original implementation exactly\n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.kernel_1, self.kernel_2, self.bias_1, self.bias_2 = [], [], [], []\n",
    "        super(GaussianLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Build the weights and biases.\"\"\"\n",
    "        n_weight_rows = input_shape[2]\n",
    "        self.kernel_1 = self.add_weight(\n",
    "            name=\"kernel_1\",\n",
    "            shape=(n_weight_rows, self.output_dim),\n",
    "            initializer=glorot_normal(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.kernel_2 = self.add_weight(\n",
    "            name=\"kernel_2\",\n",
    "            shape=(n_weight_rows, self.output_dim),\n",
    "            initializer=glorot_normal(),\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias_1 = self.add_weight(\n",
    "            name=\"bias_1\",\n",
    "            shape=(self.output_dim,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.bias_2 = self.add_weight(\n",
    "            name=\"bias_2\",\n",
    "            shape=(self.output_dim,),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        super(GaussianLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Do the layer computation.\"\"\"\n",
    "        output_mu = K.dot(x, self.kernel_1) + self.bias_1\n",
    "        output_sig = K.dot(x, self.kernel_2) + self.bias_2\n",
    "        output_sig_pos = K.softplus(output_sig) + 1e-6\n",
    "        return [output_mu, output_sig_pos]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\"Calculate the output dimensions.\"\"\"\n",
    "        return [(input_shape[0], self.output_dim), (input_shape[0], self.output_dim)]\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"Required for proper serialization\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({'output_dim': self.output_dim})\n",
    "        return config\n",
    "\n",
    "def gaussian_likelihood(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Exact copy of your gaussian_likelihood function - needed for model loading\n",
    "    \"\"\"\n",
    "    mu = y_pred[..., 0]\n",
    "    sigma = y_pred[..., 1]\n",
    "\n",
    "    # Safe clipping\n",
    "    sigma = tf.clip_by_value(sigma, 1e-3, 1e2)\n",
    "\n",
    "    # Reshape target to match mu shape\n",
    "    y_true = tf.squeeze(y_true, axis=-1)\n",
    "    y_true = tf.reshape(y_true, tf.shape(mu))\n",
    "\n",
    "    nll = (\n",
    "        0.5 * tf.math.log(2.0 * math.pi)\n",
    "        + tf.math.log(sigma)\n",
    "        + tf.square(y_true - mu) / (2.0 * tf.square(sigma))\n",
    "    )\n",
    "\n",
    "    tf.print(\"loss step range:\", tf.reduce_min(nll), tf.reduce_max(nll))\n",
    "\n",
    "    return tf.reduce_mean(nll)"
   ],
   "id": "6a97668f6d176a0a",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:41:25.326118Z",
     "start_time": "2025-09-22T19:41:25.308597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DeepARTestPipeline:\n",
    "    def __init__(self, test_data_path, model_path, scaler_path, config_path):\n",
    "        \"\"\"\n",
    "        Standalone DeepAR testing pipeline with custom layer support\n",
    "        \"\"\"\n",
    "\n",
    "        self.test_data_path = test_data_path\n",
    "        self.model_path = model_path\n",
    "        self.scaler_path = scaler_path\n",
    "        self.config_path = config_path\n",
    "\n",
    "        # Load configuration\n",
    "        print(\"Loading model configuration...\")\n",
    "        with open(config_path, 'rb') as f:\n",
    "            self.config = pickle.load(f)\n",
    "\n",
    "        self.context_length = self.config['context_length']\n",
    "        self.prediction_length = self.config['prediction_length']\n",
    "        self.n_steps = self.config['n_steps']\n",
    "        self.dimensions = self.config['dimensions']\n",
    "\n",
    "        # Load trained scaler\n",
    "        print(\"Loading trained scaler.\")\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            self.scaler = pickle.load(f)\n",
    "\n",
    "        # Load test data\n",
    "        print(\"Loading test data.\")\n",
    "        with open(test_data_path, 'r') as f:\n",
    "            self.test_data = json.load(f)\n",
    "\n",
    "        print(\"Loading DeepAR model with custom objects like learnt scaler and configurations.\")\n",
    "\n",
    "        # Define custom objects dictionary\n",
    "        custom_objects = {\n",
    "            'GaussianLayer': GaussianLayer,\n",
    "            'gaussian_likelihood': gaussian_likelihood,\n",
    "            'main_output': GaussianLayer  # Alternative name that might be used\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            self.model = load_model(model_path, custom_objects=custom_objects, compile=False)\n",
    "            print(\" Model loaded successfully!\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error loading model: {e}\")\n",
    "            print(\"Trying alternative loading method...\")\n",
    "            # Try with custom object scope\n",
    "            with tf.keras.utils.custom_object_scope(custom_objects):\n",
    "                self.model = load_model(model_path, compile=False)\n",
    "            print(\" Model loaded with custom object scope!\")\n",
    "\n",
    "        print(f\"\\n Pipeline Summary:\")\n",
    "        print(f\"  - Test samples: {len(self.test_data)}\")\n",
    "        print(f\"  - Context length: {self.context_length}\")\n",
    "        print(f\"  - Model dimensions: {self.dimensions}\")\n",
    "        print(f\"  - Model file: {model_path}\")\n",
    "        print(f\"  - Scaler loaded: \")\n",
    "        print(f\"  - Model loaded: \")\n",
    "\n",
    "    def safe_log_returns(self, prices):\n",
    "        \"\"\"Calculate safe log returns - IDENTICAL to training preprocessing\"\"\"\n",
    "        raw_price_series = np.array(prices)\n",
    "        epsilon = 1e-8\n",
    "        safe_prices = np.maximum(raw_price_series, epsilon)\n",
    "        price_ratios = safe_prices[1:] / safe_prices[:-1]\n",
    "        price_ratios = np.clip(price_ratios, epsilon, 1 / epsilon)\n",
    "        log_returns = np.log(price_ratios)\n",
    "        log_returns = np.nan_to_num(log_returns, nan=0.0, posinf=0.1, neginf=-0.1)\n",
    "        return log_returns\n",
    "\n",
    "    def preprocess_sample(self, sample):\n",
    "        \"\"\"Preprocess single test sample - IDENTICAL to training preprocessing\"\"\"\n",
    "        log_returns = self.safe_log_returns(sample['target'])\n",
    "        dynamic_features = np.array(sample['feat_dynamic_real'])\n",
    "        scaled_features = self.scaler.transform(dynamic_features.T).T\n",
    "        price_feature = np.insert(log_returns, 0, 0)\n",
    "        full_features = np.vstack([price_feature.reshape(1, -1), scaled_features])\n",
    "        return log_returns, full_features\n",
    "\n",
    "    def create_test_sequences(self):\n",
    "        \"\"\"Create test sequences for evaluation\"\"\"\n",
    "        print(\"Creating test sequences...\")\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        actual_prices = []\n",
    "\n",
    "        for sample_idx, sample in enumerate(self.test_data):\n",
    "            log_returns, full_features = self.preprocess_sample(sample)\n",
    "            total_length = len(log_returns)\n",
    "\n",
    "            if total_length <= self.context_length:\n",
    "                print(f\"  Warning: Sample {sample_idx} too short ({total_length} <= {self.context_length})\")\n",
    "                continue\n",
    "\n",
    "            for start_idx in range(0, total_length - self.context_length):\n",
    "                x_series = full_features[:, start_idx:start_idx + self.context_length].T\n",
    "                y_target = log_returns[start_idx + self.context_length - 1:start_idx + self.context_length]\n",
    "\n",
    "                if len(y_target) > 0:\n",
    "                    sequences.append(x_series)\n",
    "                    targets.append(y_target[0])\n",
    "                    actual_prices.append({\n",
    "                        'sample_idx': sample_idx,\n",
    "                        'start_idx': start_idx,\n",
    "                        'target_log_return': y_target[0]\n",
    "                    })\n",
    "\n",
    "        print(f\" Created {len(sequences)} test sequences from {len(self.test_data)} samples\")\n",
    "        return np.array(sequences), np.array(targets), actual_prices\n",
    "\n",
    "    def generate_predictions(self, sequences):\n",
    "        \"\"\"Generate predictions from the model\"\"\"\n",
    "        print(f\" Generating predictions for {len(sequences)} sequences...\")\n",
    "\n",
    "        if len(sequences) == 0:\n",
    "            print(\" ERROR: No sequences to predict!\")\n",
    "            return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "        print(f\"Input shape: {sequences.shape}\")\n",
    "\n",
    "        # Get model predictions\n",
    "        try:\n",
    "            predictions = self.model.predict(sequences, batch_size=32, verbose=1)\n",
    "            print(f\" Predictions generated successfully!\")\n",
    "            print(f\"Output shape: {predictions.shape}\")\n",
    "        except Exception as e:\n",
    "            print(f\" Error during prediction: {e}\")\n",
    "            print(\"Trying with smaller batch size. \")\n",
    "            predictions = self.model.predict(sequences, batch_size=8, verbose=1)\n",
    "\n",
    "        # Split into mu and sigma (assuming concatenated output)\n",
    "        mu = predictions[:, :, 0]  # Mean predictions\n",
    "        sigma = predictions[:, :, 1]  # Uncertainty predictions\n",
    "\n",
    "        # Use the last time step for point forecasts\n",
    "        mu_forecast = mu[:, -1]\n",
    "        sigma_forecast = sigma[:, -1]\n",
    "\n",
    "        # Ensure sigma is positive and reasonable\n",
    "        sigma_forecast = np.maximum(sigma_forecast, 1e-6)\n",
    "        sigma_forecast = np.minimum(sigma_forecast, 10.0)\n",
    "\n",
    "        print(f\" Prediction Summary:\")\n",
    "        print(f\"  - μ range: [{np.min(mu_forecast):.4f}, {np.max(mu_forecast):.4f}]\")\n",
    "        print(f\"  - σ range: [{np.min(sigma_forecast):.4f}, {np.max(sigma_forecast):.4f}]\")\n",
    "\n",
    "        # Sample from the learned distributions\n",
    "        sampled_predictions = np.random.normal(\n",
    "            loc=mu_forecast,\n",
    "            scale=np.sqrt(np.maximum(sigma_forecast, 1e-8))\n",
    "        )\n",
    "\n",
    "        return mu_forecast, sigma_forecast, sampled_predictions\n",
    "\n",
    "    def calculate_metrics(self, targets, predictions):\n",
    "        \"\"\"Calculate evaluation metrics\"\"\"\n",
    "        if len(targets) == 0 or len(predictions) == 0:\n",
    "            return {'error': 'No data for metrics calculation'}\n",
    "\n",
    "        mse = mean_squared_error(targets, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(targets, predictions)\n",
    "\n",
    "        # Directional accuracy\n",
    "        direction_correct = np.mean(np.sign(targets) == np.sign(predictions)) * 100\n",
    "\n",
    "        return {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'Directional_Accuracy_%': direction_correct,\n",
    "            'Num_Predictions': len(targets)\n",
    "        }\n",
    "\n",
    "    def run_evaluation(self):\n",
    "        \"\"\"Run complete evaluation pipeline\"\"\"\n",
    "\n",
    "        sequences, targets, price_info = self.create_test_sequences()\n",
    "\n",
    "        if len(sequences) == 0:\n",
    "            print(\" ERROR: No valid sequences created from test data!\")\n",
    "            print(\"Check that your test data has sufficient length per sample.\")\n",
    "            return None\n",
    "\n",
    "        # Generate predictions\n",
    "        mu_pred, sigma_pred, sampled_pred = self.generate_predictions(sequences)\n",
    "\n",
    "        if len(mu_pred) == 0:\n",
    "            print(\" ERROR: No predictions generated!\")\n",
    "            return None\n",
    "\n",
    "        print(\"\\n Calculating evaluation metrics.\")\n",
    "        metrics = self.calculate_metrics(targets, mu_pred)\n",
    "\n",
    "        print(\" EVALUATION RESULTS\")\n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float) and metric != 'MAPE':\n",
    "                print(f\"{metric:25}: {value:.6f}\")\n",
    "            elif metric == 'MAPE':\n",
    "                if value == float('inf'):\n",
    "                    print(f\"{metric:25}: N/A (division by zero)\")\n",
    "                else:\n",
    "                    print(f\"{metric:25}: {value:.2f}%\")\n",
    "            else:\n",
    "                print(f\"{metric:25}: {value}\")\n",
    "\n",
    "        # Create comprehensive results\n",
    "        results = {\n",
    "            'metrics': metrics,\n",
    "            'predictions': {\n",
    "                'mu': mu_pred.tolist(),\n",
    "                'sigma': sigma_pred.tolist(),\n",
    "                'sampled': sampled_pred.tolist(),\n",
    "                'targets': targets.tolist()\n",
    "            },\n",
    "            'config': self.config,\n",
    "            'test_info': {\n",
    "                'num_test_samples': len(self.test_data),\n",
    "                'num_sequences': len(sequences),\n",
    "                'sequence_length': self.context_length,\n",
    "                'model_dimensions': self.dimensions\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Save detailed results\n",
    "        with open('test_results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(\" Results saved to 'test_results.json'\")\n",
    "\n",
    "        # # Generate visualizations\n",
    "        # print(\" Creating visualizations...\")\n",
    "        # self.create_visualizations(targets, mu_pred, sigma_pred, sampled_pred)\n",
    "\n",
    "        return results\n",
    "\n",
    "    # def create_visualizations(self, targets, mu_pred, sigma_pred, sampled_pred):\n",
    "    #     \"\"\"Create comprehensive evaluation visualizations\"\"\"\n",
    "    #     if len(targets) == 0:\n",
    "    #         print(\"  No data to visualize\")\n",
    "    #         return\n",
    "    # \n",
    "    #     n_plot = min(200, len(targets))\n",
    "    # \n",
    "    #     plt.figure(figsize=(16, 12))\n",
    "    # \n",
    "    #     # Plot 1: Time Series Predictions\n",
    "    #     plt.subplot(2, 3, 1)\n",
    "    #     x_range = range(n_plot)\n",
    "    #     plt.plot(x_range, targets[:n_plot], label='Actual', color='blue', alpha=0.8, linewidth=1.5)\n",
    "    #     plt.plot(x_range, mu_pred[:n_plot], label='Predicted (μ)', color='red', alpha=0.8, linewidth=1.5)\n",
    "    # \n",
    "    #     # Confidence intervals\n",
    "    #     upper_bound = (mu_pred + 1.96 * sigma_pred)[:n_plot]\n",
    "    #     lower_bound = (mu_pred - 1.96 * sigma_pred)[:n_plot]\n",
    "    #     plt.fill_between(x_range, lower_bound, upper_bound,\n",
    "    #                      alpha=0.2, color='red', label='95% Confidence')\n",
    "    # \n",
    "    #     plt.title('DeepAR: Predictions vs Actual Values', fontsize=14, fontweight='bold')\n",
    "    #     plt.xlabel('Time Step')\n",
    "    #     plt.ylabel('Log Returns')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True, alpha=0.3)\n",
    "    # \n",
    "    # \n",
    "    #     # Plot 3: Residuals Analysis\n",
    "    #     plt.subplot(2, 3, 3)\n",
    "    #     residuals = targets[:n_plot] - mu_pred[:n_plot]\n",
    "    #     plt.plot(residuals, alpha=0.7, color='purple', linewidth=1)\n",
    "    #     plt.axhline(y=0, color='red', linestyle='--', alpha=0.8, linewidth=2)\n",
    "    #     plt.axhline(y=np.mean(residuals), color='orange', linestyle=':', alpha=0.8, linewidth=2,\n",
    "    #                 label=f'Mean: {np.mean(residuals):.4f}')\n",
    "    # \n",
    "    #     plt.title('Residuals Analysis', fontsize=14, fontweight='bold')\n",
    "    #     plt.xlabel('Time Step')\n",
    "    #     plt.ylabel('Residual (Actual - Predicted)')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True, alpha=0.3)\n",
    "    # \n",
    "    #     # Plot 4: Uncertainty Distribution\n",
    "    #     plt.subplot(2, 3, 4)\n",
    "    #     plt.hist(sigma_pred, bins=40, alpha=0.7, color='green', edgecolor='black', density=True)\n",
    "    #     plt.axvline(np.mean(sigma_pred), color='red', linestyle='--', linewidth=2,\n",
    "    #                 label=f'Mean σ: {np.mean(sigma_pred):.4f}')\n",
    "    #     plt.axvline(np.median(sigma_pred), color='blue', linestyle=':', linewidth=2,\n",
    "    #                 label=f'Median σ: {np.median(sigma_pred):.4f}')\n",
    "    # \n",
    "    #     plt.title('Predicted Uncertainty (σ) Distribution', fontsize=14, fontweight='bold')\n",
    "    #     plt.xlabel('Sigma (Standard Deviation)')\n",
    "    #     plt.ylabel('Density')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True, alpha=0.3)\n",
    "    # \n",
    "    #     # Plot 5: Prediction Intervals Coverage\n",
    "    #     plt.subplot(2, 3, 5)\n",
    "    #     # Calculate coverage of prediction intervals\n",
    "    #     coverage_80 = np.mean((targets <= mu_pred + 1.28 * sigma_pred) &\n",
    "    #                           (targets >= mu_pred - 1.28 * sigma_pred)) * 100\n",
    "    #     coverage_95 = np.mean((targets <= mu_pred + 1.96 * sigma_pred) &\n",
    "    #                           (targets >= mu_pred - 1.96 * sigma_pred)) * 100\n",
    "    # \n",
    "    #     coverages = [coverage_80, coverage_95]\n",
    "    #     expected = [80, 95]\n",
    "    #     intervals = ['80%', '95%']\n",
    "    # \n",
    "    #     x_pos = np.arange(len(intervals))\n",
    "    #     plt.bar(x_pos, coverages, alpha=0.7, color=['orange', 'red'], label='Actual')\n",
    "    #     plt.plot(x_pos, expected, 'ko-', linewidth=2, markersize=8, label='Expected')\n",
    "    # \n",
    "    #     plt.title('Prediction Interval Coverage', fontsize=14, fontweight='bold')\n",
    "    #     plt.xlabel('Confidence Interval')\n",
    "    #     plt.ylabel('Coverage (%)')\n",
    "    #     plt.xticks(x_pos, intervals)\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True, alpha=0.3)\n",
    "    # \n",
    "    #     # Add coverage percentages as text\n",
    "    #     for i, (actual, exp) in enumerate(zip(coverages, expected)):\n",
    "    #         plt.text(i, actual + 2, f'{actual:.1f}%', ha='center', fontweight='bold')\n",
    "    # \n",
    "    #     # Plot 6: Error Distribution\n",
    "    #     plt.subplot(2, 3, 6)\n",
    "    #     errors = targets - mu_pred\n",
    "    #     plt.hist(errors, bins=40, alpha=0.7, color='red', edgecolor='black', density=True)\n",
    "    #     plt.axvline(0, color='black', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    #     plt.axvline(np.mean(errors), color='blue', linestyle=':', linewidth=2,\n",
    "    #                 label=f'Mean Error: {np.mean(errors):.4f}')\n",
    "    # \n",
    "    #     plt.title('Prediction Error Distribution', fontsize=14, fontweight='bold')\n",
    "    #     plt.xlabel('Prediction Error')\n",
    "    #     plt.ylabel('Density')\n",
    "    #     plt.legend()\n",
    "    #     plt.grid(True, alpha=0.3)\n",
    "    # \n",
    "    #     plt.tight_layout()\n",
    "    #     plt.savefig('deepar_evaluation_plots.png', dpi=300, bbox_inches='tight')\n",
    "    #     plt.show()\n",
    "    #     print(\" Visualizations saved to 'deepar_evaluation_plots.png'\")"
   ],
   "id": "10eb54a9494193eb",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:41:25.598197Z",
     "start_time": "2025-09-22T19:41:25.591493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function with enhanced error handling\"\"\"\n",
    "\n",
    "    TEST_DATA_PATH = 'C:\\\\Users\\\\mjaye\\\\PycharmProjects\\\\DevJFintellect\\\\testing_data.json'  # Your test data file\n",
    "    MODEL_PATH = 'C:\\\\Users\\\\mjaye\\\\PycharmProjects\\\\DevJFintellect\\\\model\\\\deepar_stock_forecaster.keras'\n",
    "    SCALER_PATH = 'C:\\\\Users\\\\mjaye\\\\PycharmProjects\\\\DevJFintellect\\\\model\\\\trained_scaler.pkl'\n",
    "    CONFIG_PATH = 'C:\\\\Users\\\\mjaye\\\\PycharmProjects\\\\DevJFintellect\\\\model\\\\model_config.pkl'\n",
    "\n",
    "\n",
    "    required_files = {\n",
    "        'Model': MODEL_PATH,\n",
    "        'Scaler': SCALER_PATH,\n",
    "        'Config': CONFIG_PATH,\n",
    "        'Test Data': TEST_DATA_PATH\n",
    "    }\n",
    "\n",
    "    missing_files = []\n",
    "    for name, path in required_files.items():\n",
    "        if os.path.exists(path):\n",
    "            size = os.path.getsize(path)\n",
    "            print(f\"   {name}: {path} ({size:,} bytes)\")\n",
    "        else:\n",
    "            print(f\"   {name}: {path} (NOT FOUND)\")\n",
    "            missing_files.append(path)\n",
    "\n",
    "    if missing_files:\n",
    "        print(f\"\\n ERROR: Missing required files: {missing_files}\")\n",
    "        return\n",
    "\n",
    "    # Run evaluation pipeline\n",
    "    try:\n",
    "        print(\"\\n Initializing pipeline. \")\n",
    "        pipeline = DeepARTestPipeline(\n",
    "            test_data_path=TEST_DATA_PATH,\n",
    "            model_path=MODEL_PATH,\n",
    "            scaler_path=SCALER_PATH,\n",
    "            config_path=CONFIG_PATH\n",
    "        )\n",
    "\n",
    "        # Run full evaluation\n",
    "        print(\"\\n Running evaluation. \")\n",
    "        results = pipeline.run_evaluation()\n",
    "\n",
    "        if results is not None:\n",
    "            print(\" SUCCESS! Testing pipeline completed successfully!\")\n",
    "            print(\"\\n Generated files:\")\n",
    "            print(\" test_results.json - Detailed metrics and predictions\")\n",
    "\n",
    "            # Quick summary\n",
    "            metrics = results['metrics']\n",
    "            print(f\"\\n Quick Summary:\")\n",
    "            print(f\"  • RMSE: {metrics.get('RMSE', 'N/A'):.4f}\")\n",
    "            print(f\"  • MAE: {metrics.get('MAE', 'N/A'):.4f}\")\n",
    "            print(f\"  • Directional Accuracy: {metrics.get('Directional_Accuracy_%', 'N/A'):.1f}%\")\n",
    "            print(f\"  • Number of Predictions: {metrics.get('Num_Predictions', 'N/A')}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n Testing pipeline failed! Check the error messages above.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n CRITICAL ERROR in testing pipeline:\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        print(\"\\n Full traceback:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ],
   "id": "af6c0668feab954c",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:41:26.479550Z",
     "start_time": "2025-09-22T19:41:26.008193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "c081126ee32e3cbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: C:\\Users\\mjaye\\PycharmProjects\\DevJFintellect\\model\\deepar_stock_forecaster.keras (548,599 bytes)\n",
      "   Scaler: C:\\Users\\mjaye\\PycharmProjects\\DevJFintellect\\model\\trained_scaler.pkl (802 bytes)\n",
      "   Config: C:\\Users\\mjaye\\PycharmProjects\\DevJFintellect\\model\\model_config.pkl (188 bytes)\n",
      "   Test Data: C:\\Users\\mjaye\\PycharmProjects\\DevJFintellect\\testing_data.json (814,371 bytes)\n",
      "\n",
      " Initializing pipeline. \n",
      "Loading model configuration...\n",
      "Loading trained scaler.\n",
      "Loading test data.\n",
      "Loading DeepAR model with custom objects like learnt scaler and configurations.\n",
      " Model loaded successfully!\n",
      "\n",
      " Pipeline Summary:\n",
      "  - Test samples: 247\n",
      "  - Context length: 4\n",
      "  - Model dimensions: 9\n",
      "  - Model file: C:\\Users\\mjaye\\PycharmProjects\\DevJFintellect\\model\\deepar_stock_forecaster.keras\n",
      "  - Scaler loaded: \n",
      "  - Model loaded: \n",
      "\n",
      " Running evaluation. \n",
      "Creating test sequences...\n",
      " Created 1976 test sequences from 247 samples\n",
      " Generating predictions for 1976 sequences...\n",
      "Input shape: (1976, 4, 9)\n",
      "\u001B[1m62/62\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step\n",
      " Predictions generated successfully!\n",
      "Output shape: (1976, 4, 2)\n",
      " Prediction Summary:\n",
      "  - μ range: [0.0698, 0.3646]\n",
      "  - σ range: [0.1179, 0.2531]\n",
      "\n",
      " Calculating evaluation metrics.\n",
      " EVALUATION RESULTS\n",
      "MSE                      : 0.029300\n",
      "RMSE                     : 0.171174\n",
      "MAE                      : 0.136133\n",
      "Directional_Accuracy_%   : 64.574899\n",
      "Num_Predictions          : 1976\n",
      " Results saved to 'test_results.json'\n",
      " SUCCESS! Testing pipeline completed successfully!\n",
      "\n",
      " Generated files:\n",
      " test_results.json - Detailed metrics and predictions\n",
      "\n",
      " Quick Summary:\n",
      "  • RMSE: 0.1712\n",
      "  • MAE: 0.1361\n",
      "  • Directional Accuracy: 64.6%\n",
      "  • Number of Predictions: 1976\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "39f38ab497d97afa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
